# localrules: serialize_fastp, serialize_fqscreen, serialize_ivar, serialize_qualimap, get_json
#define sample_id_pattern wildcard and accessing sample_sheet
import pandas as pd, re, os
sys.path.insert(0, config['subscript_path'])
from covipipe_utilities import Wrapper as wp

sip_wild = config['work_dir']+'{sample_id_pattern}_R[1,2]_001.fastq.gz'
sample_sheet = pd.read_csv(f"{config['output_directory']}sample_sheet.csv")

def get_mem_mb(wildcards, threads):
    return threads * 512

#AGGREGATION RULE
rule all:
    input:
        config["assembly_target_files"],
        multiqc_sif = config['multiqc_sif']
    envmodules:
        'singularity'
    threads:
        config['multiqc']['multiqc_threads']
    shell:
        '''
        if [ -f {config[output_directory]}multiqc_report.html ]; then
            echo echo Sample assembly finished, multiqc finished before.
        else
            echo Sample assembly finished, starting multiqc.
            singularity run {input.multiqc_sif} multiqc {config[output_directory]} -o {config[output_directory]} --flat
        fi
        '''

        

rule adapter_removal: #ok
    input:
        sif_file = config["fastq_sif"],
        read_1 = config['work_dir']+'{sample_id_pattern}_R1_001.fastq.gz',
        read_2 = config['work_dir']+'{sample_id_pattern}_R2_001.fastq.gz'
    envmodules:
        'singularity'
    output:
        read_1 = temp(config['work_dir']+'{sample_id_pattern}_adapter_trimmed_R1.fastq.gz'),
        read_2 = temp(config['work_dir']+'{sample_id_pattern}_adapter_trimmed_R2.fastq.gz'),
        cutadapt_report = config['output_directory']+'{sample_id_pattern}_cutadapt_log.txt'
    shell:
        '''
        touch {output.read_1}
        touch {output.read_2}
        singularity run {input.sif_file} cutadapt -a {config[cutadapt][forward_adapter]} -A {config[cutadapt][reverse_adapter]} -o {output.read_1} -p {output.read_2} "{input.read_1}" "{input.read_2}" > {output.cutadapt_report}
        '''


rule quality_control: #ok
    input:
        sif_file = config["fastq_sif"], 
        read_1 = config['work_dir']+'{sample_id_pattern}_adapter_trimmed_R1.fastq.gz',
        read_2 = config['work_dir']+'{sample_id_pattern}_adapter_trimmed_R2.fastq.gz'
    # envmodules:
    #     'singularity'
    output:
        read_1 = temp(config['work_dir']+'{sample_id_pattern}_quality_filtered_R1.fastq.gz'),
        read_2 = temp(config['work_dir']+'{sample_id_pattern}_quality_filtered_R2.fastq.gz'),
        fastp_report_html = config['output_directory']+'{sample_id_pattern}_fastp_report.html',
        fastp_report_json = config['output_directory']+'{sample_id_pattern}_fastp_report.json'
        
    run:
        os.system(
f"""
module load singularity
singularity run {input.sif_file} fastp -y -p -h {output.fastp_report_html} -j {output.fastp_report_json} -i {input.read_1} -I {input.read_2} -o {output.read_1} -O {output.read_2} -l {config['fastp']['fastp_length_filter']} -q {config['fastp']['fastp_quality_filter']}
"""
        )
        

rule serialize_fastp:
    input:
        fastp_report_json = config['output_directory']+'{sample_id_pattern}_fastp_report.json'
    output:
        config['output_directory']+'{sample_id_pattern}_fastp_et.json'
    run:
        wp.parse_fastp(wildcards.sample_id_pattern, input.fastp_report_json)  


rule read_alignment: #ok
    input:
        sif_file = config["fastq_sif"], 
        read_1 = config['work_dir']+'{sample_id_pattern}_quality_filtered_R1.fastq.gz',
        read_2 = config['work_dir']+'{sample_id_pattern}_quality_filtered_R2.fastq.gz'
    envmodules:
        'singularity'
    output:
        sorted_bam = config['output_directory']+'{sample_id_pattern}_sorted.bam'
    shell:
        """
        singularity run {input.sif_file} bwa mem {config[reference_path]} -v {config[bwa_verbose_level]} {input.read_1} {input.read_2} | singularity run {input.sif_file} samtools view -bS - | singularity run {input.sif_file} samtools sort -o {output.sorted_bam}
        """     


rule primer_trimming: #ok
    input:
        sif_file = config["fastq_sif"],
        sorted_bam = config['output_directory']+'{sample_id_pattern}_sorted.bam'
    # envmodules:
    #     'singularity'
    output:
        trimmed_bam = temp(config['output_directory']+'{sample_id_pattern}_trimmed.bam'),
        index_1 = temp(config['output_directory']+'{sample_id_pattern}_sorted.bam.bai'),
        sortrimmed_bam = temp(config['output_directory']+'{sample_id_pattern}_trimmed_sorted.bam'),
        index_2 = temp(config['output_directory']+'{sample_id_pattern}_trimmed_sorted.bam.bai'),
        ivar_log = config['output_directory']+'{sample_id_pattern}_ivar_log.txt'
    run:
        os.system(
f"""
module load singularity
singularity run {input.sif_file} samtools index {input.sorted_bam}
singularity run {input.sif_file} ivar trim -e -b {config['ivar']['primer_path']} -p {output.trimmed_bam} -i {input.sorted_bam} > {output.ivar_log}
singularity run {input.sif_file} samtools sort -o {output.sortrimmed_bam} {output.trimmed_bam}
singularity run {input.sif_file} samtools index {output.sortrimmed_bam}
"""
        )
        

rule serialize_ivar:
    input:
        ivar_log = config['output_directory']+'{sample_id_pattern}_ivar_log.txt'
    output:
        config['output_directory']+'{sample_id_pattern}_ivar_et.json'
    run:
        wp.parse_ivar(wildcards.sample_id_pattern, input.ivar_log)


rule indel_realignment: #ok
    input:
        sif_file = config["fastq_sif"],
        sortrimmed_bam = config['output_directory']+'{sample_id_pattern}_trimmed_sorted.bam',
        index_2 = config['output_directory']+'{sample_id_pattern}_trimmed_sorted.bam.bai',
        read_1 = config['work_dir']+'{sample_id_pattern}_R1_001.fastq.gz'
    envmodules:
        'singularity'
    threads:
        config['abra']["abra_rule_cpus"]
    resources:
        mem_mb = get_mem_mb
    output:
        sortrimmed_bed = temp(config['work_dir']+'{sample_id_pattern}_trimmed_sorted.bed'),
        realigned_bam = temp(config['work_dir']+'{sample_id_pattern}_unsort_markd.bam')
    shell:
        """
        [[ -d {config[work_dir]}tmpdir_{wildcards.sample_id_pattern}/ ]] && rm -r {config[work_dir]}tmpdir_{wildcards.sample_id_pattern}/
        mkdir -p {config[work_dir]}tmpdir_{wildcards.sample_id_pattern}/

        if [ $(zcat {input.read_1} | echo $((`wc -l`/(4)))) -gt {config[picard][dedup_threshold]} ]; then
            java -jar {config[picard][picard_jar_path]} MarkDuplicates -I {input.sortrimmed_bam} -O {config[work_dir]}{wildcards.sample_id_pattern}_trimmed_dedup.bam -M {config[output_directory]}{wildcards.sample_id_pattern}_picard_dp.txt --REMOVE_DUPLICATES
            singularity run {input.sif_file} samtools sort -o {config[work_dir]}{wildcards.sample_id_pattern}_trimmed_sorted_dedup.bam {config[work_dir]}{wildcards.sample_id_pattern}_trimmed_dedup.bam
            singularity run {input.sif_file} samtools index {config[work_dir]}{wildcards.sample_id_pattern}_trimmed_sorted_dedup.bam
            singularity run {input.sif_file} bedtools bamtobed -i {config[work_dir]}{wildcards.sample_id_pattern}_trimmed_sorted_dedup.bam > {output.sortrimmed_bed}
            java -jar -Xmx$(({resources.mem_mb}/(1024) - 1/2))G {config[abra][abra_jar_path]} --threads {threads} --in {config[work_dir]}{wildcards.sample_id_pattern}_trimmed_sorted_dedup.bam --out {output.realigned_bam} --ref {config[reference_path]} --targets {output.sortrimmed_bed} --tmpdir {config[work_dir]}tmpdir_{wildcards.sample_id_pattern}/
            rm {config[work_dir]}{wildcards.sample_id_pattern}_trimmed_dedup.bam
            rm {config[work_dir]}{wildcards.sample_id_pattern}_trimmed_sorted_dedup.bam
            rm {config[work_dir]}{wildcards.sample_id_pattern}_trimmed_sorted_dedup.bam.bai
        else
            singularity run {input.sif_file} bedtools bamtobed -i {input.sortrimmed_bam} > {output.sortrimmed_bed}
            java -jar -Xmx$(({resources.mem_mb}/(1024) - 1/2))G {config[abra][abra_jar_path]} --threads {threads} --in {input.sortrimmed_bam} --out {output.realigned_bam} --ref {config[reference_path]} --targets {output.sortrimmed_bed} --tmpdir {config[work_dir]}tmpdir_{wildcards.sample_id_pattern}/
        fi
        rm -r {config[work_dir]}tmpdir_{wildcards.sample_id_pattern}/
        """


rule alignment_quality_control: #ok
    input:
        config['output_directory']+'{sample_id_pattern}_qualimap/'+'raw_data_qualimapReport/coverage_across_reference.txt',
        config['output_directory']+'{sample_id_pattern}_qualimap/'+'raw_data_qualimapReport/mapping_quality_across_reference.txt',
        sif_file = config["fastq_sif"],
        qualimap_path = config['qualimap']["qualimap_sif_path"],
        sorted_raw_bam = config['output_directory']+'{sample_id_pattern}_sorted.bam',
        realigned_bam = config['work_dir']+'{sample_id_pattern}_unsort_markd.bam',
    output:
        flagstat_report = config['output_directory']+'{sample_id_pattern}_mapped_report.txt',
        sequencing_depth = config['output_directory']+'{sample_id_pattern}_seq_depth.txt',
        sorted_realigned_bam = temp(config['output_directory']+'{sample_id_pattern}_markd.bam'),
        index = temp(config['output_directory']+'{sample_id_pattern}_markd.bam.bai'),
        qualimap_report = config['output_directory']+'{sample_id_pattern}_qualimap/qualimapReport.html'
    # envmodules:
    #     'singularity'
    run:
        os.system(
f"""
module load singularity
singularity run {input.sif_file} samtools flagstat {input.sorted_raw_bam} > {output.flagstat_report};
singularity run {input.sif_file} samtools sort -o {output.sorted_realigned_bam} {input.realigned_bam};
singularity run {input.sif_file} samtools index {output.sorted_realigned_bam};
singularity run {input.sif_file} samtools depth {output.sorted_realigned_bam} > {output.sequencing_depth};
mkdir -p {config['output_directory']}{wildcards.sample_id_pattern}_qualimap;
singularity run {input.qualimap_path} qualimap bamqc -bam {output.sorted_realigned_bam} -outdir {config['output_directory']}{wildcards.sample_id_pattern}_qualimap --java-mem-size={config['qualimap']['qualimap_memory_limit_gb']}G || echo WARNING: No reads mapped to the reference -- {output.sorted_realigned_bam}; touch {output.qualimap_report}
"""
            )


rule serialize_qualimap:
    input:
        ref_cov = config['output_directory']+'{sample_id_pattern}_qualimap/'+'raw_data_qualimapReport/coverage_across_reference.txt',
        ref_qual = config['output_directory']+'{sample_id_pattern}_qualimap/'+'raw_data_qualimapReport/mapping_quality_across_reference.txt',
        flagstat_report = config['output_directory']+'{sample_id_pattern}_mapped_report.txt'
    output:
        config['output_directory']+'{sample_id_pattern}_samtools_et.json',
        config['output_directory']+'{sample_id_pattern}_qualimap_et.json'
    run:
        wp.parse_qualimap(
            wildcards.sample_id_pattern,
            input.ref_cov, 
            input.ref_qual
            )
        wp.parse_samtools(wildcards.sample_id_pattern, input.flagstat_report)




rule variant_calling: #ok
    input:
        sif_file = config["fastq_sif"],
        index = config['output_directory']+'{sample_id_pattern}_markd.bam.bai',
        sorted_realigned_bam = config['output_directory']+'{sample_id_pattern}_markd.bam'
    output:
        vcf = config['output_directory']+'{sample_id_pattern}.vcf'
    envmodules:
        'singularity'
    shell:
        """
        singularity run {input.sif_file} freebayes -f {config[reference_path]} {input.sorted_realigned_bam} | singularity run {input.sif_file} vcffilter -f "( QUAL > {config[freebayes][quality_filter]} )" AND "( DP > {config[freebayes][coverage_depth_filter]} )" > {output.vcf}
        """ 


rule variant_annotation: #ok
    input:
        vcf = config['output_directory']+'{sample_id_pattern}.vcf'
    output:
        annotated_variants = temp(config['output_directory']+'{sample_id_pattern}.ann.vcf'),
    shell:
        """
        java -Xmx{config[snpEff][snpEff_memory_limit_gb]}G -jar {config[snpEff][snpEff_path]} {config[snpEff][snpEff_reference]} {input.vcf} > {output.annotated_variants}
        """

rule consensus_calling: #ok
    input:
        sif_file = config["fastq_sif"],
        sorted_realigned_bam = config['output_directory']+'{sample_id_pattern}_markd.bam'
    output:
        consensus_fasta = config['output_directory']+'{sample_id_pattern}_consensus.fasta',
        consensus_qual = temp(config['output_directory']+'{sample_id_pattern}_consensus.qual.txt')
    envmodules:
        'singularity'
    shell:
        '''
        singularity run {input.sif_file} samtools mpileup -aa -A -d {config[ivar][use_upper_depth_limit]} -Q {config[ivar][cons_quality_filter]} {input.sorted_realigned_bam} | singularity run {input.sif_file} ivar consensus -p {config[output_directory]}{wildcards.sample_id_pattern}_consensus.fa -t {config[ivar][cons_min_variant_supporting_read_fraction]} -m {config[ivar][cons_min_coverage]} -q {config[ivar][cons_quality_filter]}
        mv {config[output_directory]}{wildcards.sample_id_pattern}_consensus.fa {output.consensus_fasta}
        sed -i "s/>Consensus_{wildcards.sample_id_pattern}_consensus_threshold_0.5_quality_30/>hCoV-19\/Latvia\/{wildcards.sample_id_pattern}\/$(date +"%Y")/" {output.consensus_fasta}
        sed -i -E "s/_S[0-9]*\//\//" {output.consensus_fasta}
        '''

rule fastq_screening: #ok
    input:
        fastq_sceen_sif = config['multiqc_sif'], #'/mnt/home/groups/nmrl/image_files/fastq_screen.sif',
        read_1 = config['work_dir']+'{sample_id_pattern}_R1_001.fastq.gz',
        read_2 = config['work_dir']+'{sample_id_pattern}_R2_001.fastq.gz'
    output:
        read_1_profile_txt = config["output_directory"]+"{sample_id_pattern}_1_screen.txt",
        read_1_profile_html = config["output_directory"]+"{sample_id_pattern}_1_screen.html",
        read_2_profile_txt = config["output_directory"]+"{sample_id_pattern}_2_screen.txt",
        read_2_profile_html = config["output_directory"]+"{sample_id_pattern}_2_screen.html"
    # envmodules:
    #     'singularity'
    run:
        os.system(
f"""
module load singularity
cd /home/groups/nmrl/
downsample_r1=$(zcat {input.read_1} | echo $((`wc -l`/(4*{config['fastqscreen']['read1_downsample_fraction']}))))
downsample_r2=$(zcat {input.read_2} | echo $((`wc -l`/(4*{config['fastqscreen']['read2_downsample_fraction']}))))
singularity run {input.fastq_sceen_sif} fastq_screen --subset $downsample_r1 -conf {config['fastqscreen']['fq_screen_config']} {input.read_1} --outdir {config['output_directory']}
singularity run {input.fastq_sceen_sif} fastq_screen --subset $downsample_r2 -conf {config['fastqscreen']['fq_screen_config']} {input.read_2} --outdir {config['output_directory']}
mv {config['output_directory']}{wildcards.sample_id_pattern}_*R1*_screen.txt {output.read_1_profile_txt}
mv {config['output_directory']}{wildcards.sample_id_pattern}_*R1*_screen.html {output.read_1_profile_html}
mv {config['output_directory']}{wildcards.sample_id_pattern}_*R2*_screen.txt {output.read_2_profile_txt}
mv {config['output_directory']}{wildcards.sample_id_pattern}_*R2*_screen.html {output.read_2_profile_html}
"""
        )



rule serialize_fqscreen:
    input:
        read_1_profile_txt = config["output_directory"]+"{sample_id_pattern}_1_screen.txt",
        read_2_profile_txt = config["output_directory"]+"{sample_id_pattern}_2_screen.txt"
    output:
        config["output_directory"]+"{sample_id_pattern}_fastqscreen_et.json"
    run:
        wp.parse_fqscreen(wildcards.sample_id_pattern, input.read_1_profile_txt)
        wp.parse_fqscreen(wildcards.sample_id_pattern, input.read_2_profile_txt)



rule vcf_to_csv: #ok
    input:
        sif_file = config["fastq_sif"],
        fastq_sceen_sif = '/mnt/home/groups/nmrl/image_files/fastq_screen.sif',
        annotated_variants = config['output_directory']+'{sample_id_pattern}.ann.vcf'
    output:
        annotated_csv = config['output_directory']+'{sample_id_pattern}.ann.csv'
    envmodules:
        'singularity'
    shell:
        '''
        singularity run {input.sif_file} python {config[assembly_subscripts]}vcf_to_csv_cmd.py {input.annotated_variants} {output.annotated_csv}
        '''


rule depth_plot: #ok
    input:
        sif_file = config["fastq_sif"],
        fastq_sceen_sif = '/mnt/home/groups/nmrl/image_files/fastq_screen.sif',
        sequencing_depth = config['output_directory']+'{sample_id_pattern}_seq_depth.txt'
    output:
        sequencing_depth_plot = config['output_directory']+'{sample_id_pattern}_seq_depth_plot.html'
    envmodules:
        'singularity'
    shell:
        """
        singularity run {input.sif_file} python {config[assembly_subscripts]}depth_plot.py {input.sequencing_depth} {output.sequencing_depth_plot}
        """


rule get_json:
    input:
        samtools=config['output_directory']+'{sample_id_pattern}_samtools_et.json',
        fqs=config["output_directory"]+"{sample_id_pattern}_fastqscreen_et.json",
        qmap=config['output_directory']+'{sample_id_pattern}_qualimap_et.json',
        ivar=config['output_directory']+'{sample_id_pattern}_ivar_et.json',
        fastp=config['output_directory']+'{sample_id_pattern}_fastp_et.json'
    output:
        config['output_directory']+'{sample_id_pattern}_combined.json'
    run:
        wp.combine_jsons(wildcards.sample_id_pattern, config['output_directory'], [input.samtools, input.fqs, input.qmap, input.ivar, input.fastp])