{
    "description":"This is a wrapper script of COVIPIPE (v.0.0) NGS data processing pipeline.\n\nIt is designed to perform the analysis of paired-end (PE) Sars-CoV2 Illumina reads.\nPipeline is structured in terms of modules. Each module corresponds to a Snakemake script (snakefile) and a python module object.\nSnakefiles are used to define data processing rules. Module class objects store information about inputs and expected outputs for these rules.\nThey also handle file placement operations, module configuration, information transfer between modules,\nand other processes that are not directly involved in running analysis on files. All modules use open-source software.\n\nAssembly module is designed to process a batch of paired-end fastq files using snakemake-based job submission to HPC cluster.\nBy default it converts names of all fastq files in input folder to illumina format before processing and renames them back afterwards\nAlso by-default it performs fastq file itegrity check and excludes any damaged fastq files from the analysis (e.g. incomplete/interrupted upload issue).\nFinally, after processing is finished, it adds sample-specific processing indentifier to the name of each output file/folder (e.g. COV000001)\n\nDownstream module does not depend directly on any input from cov_assembly module. However for the results to be included in the report\nthe folder where the cov_assembly output is stored should be found under cov_analysis/covid_output/ directory and named in a specific manner:\n\nfor samples sequenced by NMRL: NMRL_LIC_analysis-date_aggregation-start-date_aggregation-end-date\nfor samples sequensed by Eurofins: NMRL_ECDC_analysis-date_aggregation-start-date_aggregation-end-date\nall dates should be given in YYYY-MM-DD format\n\nIt is designed to produce aggregated results from many analysis batches fount in cov_analysis/covid_output/ folder.\nBy default it aggregates results, performs pangolin typing, updates analysis history and mutation heatmap.\nIt also generates a report under cov_analysis/reports folder and generates log files for every step it takes.",
    "required_arguments":[
        ["-m", "--mode", "Selecting mode that allows to run specific modules of the pipeline:\nall - run all modules (starting from fastq files)\nassembly - run only cov_assembly module (starting from fastq files)\ndownstream - run only cov_downstream module (starting from fasta & fastq file)."]
    ],
    "optional":{
        "arguments":[
            ["-i", "--input", "Path to directory that contains files to be analysed (files are NOT parsed from subfolders).\nCheck config_files/json/module_data/patterns/inputs section for expected input file extensions for each module)", null],
            ["-c", "--config", "Path to the config file (if not supplied, the copy of the template config_modular.yaml will be used).", "./config_files/yaml/config_modular.yaml"],
            ["-o", "--output_dir", "Path to the output directory where the results will be stored (ardetype_output/ by-default).", "covipipe_output/"],
            ["-n", "--num_jobs", "Maximum number of jobs to be run in-parallel on different nodes of HPC (12 by-default).", 12],
            ["-d1", "--start_date", "Strating date of the date range that covers samples to be included in downstream analysis.", null],
            ["-d2", "--end_date", "Ending date of the date range that covers samples to be included in downstream analysis.", null]
        ],
        "flags":[
            ["-s", "--install_snakemake", "Flag to install mamba and snakemake for the current HPC user, if it is not already installed."],
            ["-t", "--dry_run", "Flag to test-run all snakemake rules in all modules (-np option)."],
            ["-f", "--force_all", "Flag to rerun all snakemake rules in all modules (--forceall option)."],
            ["-g", "--rule_graph", "Flag to visualize snakemage job graphs for all modules and save as pdf file (--rulegraph option)."],
            ["-l", "--clean_job_logs", "Flag to remove all job log files that are older than 30 days."],
            ["-sq", "--skip_integrity_check", "Flag to skip the integrity check of the fastq files."],
            ["-sp", "--skip_pango", "(Downstream option) Flag to skip pangolin typing when running downstream module."],
            ["-sh", "--skip_heatmap", "(Downstream option) Flag to skip mutation heatmap update when running downstream module."],
            ["-sd", "--skip_db_update", "(Downstream option) Flag to skip summary file update when running downstream module."],
            ["-st", "--skip_tessy", "(Downstream option) Flag to skip tessy report generation when running downstream module."]
        ]
    }
}
